{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0396d4da-82d2-439c-a62d-e5c5b9d092b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 1: Setup ---\n",
    "import os, re, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "DATA = Path(r\"C:\\Users\\kule9\\final\\data\")\n",
    "ART  = Path(r\"C:\\Users\\kule9\\final\\artifacts\")\n",
    "DATA.mkdir(parents=True, exist_ok=True)\n",
    "ART.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def pick_col(df, patterns, must=False, default=None, name=\"\"):\n",
    "    for pat in patterns:\n",
    "        for c in df.columns:\n",
    "            if re.search(pat, str(c), flags=re.I):\n",
    "                return c\n",
    "    if must and default is None:\n",
    "        raise RuntimeError(f\"[{name}] missing any of {patterns}; cols={list(df.columns)}\")\n",
    "    return default\n",
    "\n",
    "def map_to_binary(series):\n",
    "    s = series.copy()\n",
    "    if pd.api.types.is_numeric_dtype(s):\n",
    "        uniq = set(pd.unique(s.dropna()))\n",
    "        if uniq <= {0,1}: return s.astype(int)\n",
    "        return (s >= s.dropna().median()).astype(int)\n",
    "    low = s.astype(str).str.strip().str.lower()\n",
    "    pass_set = {\"pass\",\"passed\",\"approve\",\"approved\",\"success\",\"completed\",\"graduate\",\"graduated\",\"yes\",\"y\"}\n",
    "    fail_set = {\"fail\",\"failed\",\"withdraw\",\"withdrawn\",\"dropout\",\"incomplete\",\"no\",\"n\"}\n",
    "    out=[]\n",
    "    for v in low:\n",
    "        if v in pass_set: out.append(1)\n",
    "        elif v in fail_set: out.append(0)\n",
    "        elif v in {\"1\",\"0\"}: out.append(int(v))\n",
    "        else: out.append(np.nan)\n",
    "    out = pd.Series(out, index=s.index)\n",
    "    return out.fillna(out.mode().iloc[0] if not out.mode().empty else 0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c90c7dc7-9567-441f-b17e-9506cab48bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>institution</th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>year</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>language_level</th>\n",
       "      <th>program</th>\n",
       "      <th>current_grade</th>\n",
       "      <th>attendance</th>\n",
       "      <th>pass_fail</th>\n",
       "      <th>hofstede_idv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>INST_A</td>\n",
       "      <td>LV</td>\n",
       "      <td>Baltics</td>\n",
       "      <td>2024</td>\n",
       "      <td>F</td>\n",
       "      <td>39</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>CS</td>\n",
       "      <td>2.185283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>INST_A</td>\n",
       "      <td>LK</td>\n",
       "      <td>Asia</td>\n",
       "      <td>2024</td>\n",
       "      <td>F</td>\n",
       "      <td>37</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>ENG</td>\n",
       "      <td>3.344838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>INST_A</td>\n",
       "      <td>IN</td>\n",
       "      <td>Asia</td>\n",
       "      <td>2024</td>\n",
       "      <td>F</td>\n",
       "      <td>33</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>CS</td>\n",
       "      <td>2.078382</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>INST_A</td>\n",
       "      <td>DE</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2024</td>\n",
       "      <td>F</td>\n",
       "      <td>41</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>BA</td>\n",
       "      <td>2.628180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>INST_A</td>\n",
       "      <td>DE</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2024</td>\n",
       "      <td>M</td>\n",
       "      <td>21</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>BA</td>\n",
       "      <td>2.448369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   student_id institution country   region  year gender  age language_level  \\\n",
       "0           0      INST_A      LV  Baltics  2024      F   39        Unknown   \n",
       "1           1      INST_A      LK     Asia  2024      F   37        Unknown   \n",
       "2           2      INST_A      IN     Asia  2024      F   33        Unknown   \n",
       "3           3      INST_A      DE   Europe  2024      F   41        Unknown   \n",
       "4           4      INST_A      DE   Europe  2024      M   21        Unknown   \n",
       "\n",
       "  program  current_grade  attendance  pass_fail  hofstede_idv  \n",
       "0      CS       2.185283         NaN          1            70  \n",
       "1     ENG       3.344838         NaN          1            35  \n",
       "2      CS       2.078382         NaN          1            48  \n",
       "3      BA       2.628180         NaN          0            67  \n",
       "4      BA       2.448369         NaN          0            67  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Cell 2: Load data + merge region ---\n",
    "frames = []\n",
    "for fname, tag in [(\"institution_A.csv\",\"INST_A\"), (\"institution_B.csv\",\"INST_B\")]:\n",
    "    p = DATA/fname\n",
    "    if p.exists():\n",
    "        raw = pd.read_csv(p)\n",
    "        df = pd.DataFrame()\n",
    "        sid = pick_col(raw,[r\"^student_?id$\",r\"\\bid$\"], default=raw.columns[0])\n",
    "        df[\"student_id\"] = pd.to_numeric(raw[sid], errors=\"coerce\").fillna(-1).astype(int)\n",
    "        df[\"institution\"] = tag\n",
    "        df[\"country\"] = raw.get(pick_col(raw,[\"country\",\"iso\",\"nation\"], default=\"country\"), \"Unknown\")\n",
    "        df[\"region\"]  = raw.get(pick_col(raw,[\"region\"], default=\"region\"), \"Unknown\")\n",
    "        df[\"year\"]    = raw.get(pick_col(raw,[\"year\",\"academic_year\",\"ay\"], default=\"year\"), 2024)\n",
    "        df[\"gender\"]  = raw.get(pick_col(raw,[\"gender\",\"sex\"], default=\"gender\"), \"Unknown\")\n",
    "        df[\"age\"]     = pd.to_numeric(raw.get(pick_col(raw,[\"age\"], default=\"age\"), np.nan), errors=\"coerce\")\n",
    "        df[\"language_level\"] = raw.get(pick_col(raw,[\"language\",\"lang\",\"ielts\",\"b2\",\"c1\"], default=\"language\"), \"Unknown\")\n",
    "        df[\"program\"] = raw.get(pick_col(raw,[\"program\",\"course\",\"major\"], default=\"program\"), f\"Prog_{tag[-1]}\")\n",
    "        df[\"current_grade\"] = pd.to_numeric(raw.get(pick_col(raw,[\"gpa\",\"grade\",\"score\",\"G3\"], default=\"G3\"), np.nan), errors=\"coerce\")\n",
    "        df[\"attendance\"] = pd.to_numeric(raw.get(pick_col(raw,[\"attendance\",\"presence\",\"absences\"], default=\"attendance\"), np.nan), errors=\"coerce\")\n",
    "        tgt = pick_col(raw,[r\"^target_?success$\",r\"^success$\",r\"^pass_fail$\",r\"^passed$\",r\"^final_result$\",r\"^dropout$\",r\"^label$\"], default=None)\n",
    "        df[\"pass_fail\"] = map_to_binary(raw[tgt]) if tgt else map_to_binary(df[\"current_grade\"])\n",
    "        frames.append(df)\n",
    "\n",
    "# Synthesize small dataset if none found (so the notebook always runs)\n",
    "if not frames:\n",
    "    n=400\n",
    "    def synth(inst, countries):\n",
    "        rng=np.random.default_rng(42 if inst==\"INST_A\" else 777)\n",
    "        df=pd.DataFrame({\n",
    "            \"student_id\": np.arange(n),\n",
    "            \"institution\": inst,\n",
    "            \"country\": rng.choice(countries, n),\n",
    "            \"region\": \"Unknown\",\n",
    "            \"year\": 2024,\n",
    "            \"gender\": rng.choice(list(\"FM\"), n),\n",
    "            \"age\": rng.integers(18,45,n),\n",
    "            \"language_level\": rng.choice([\"A2\",\"B1\",\"B2\",\"C1\",\"C2\"], n),\n",
    "            \"program\": rng.choice([\"CS\",\"ENG\",\"BUS\"], n),\n",
    "            \"current_grade\": rng.normal(3.0 if inst==\"INST_A\" else 2.7, 0.7, n).clip(0,4),\n",
    "            \"attendance\": rng.uniform(60, 98, n),\n",
    "        })\n",
    "        df[\"pass_fail\"] = (0.6*df[\"current_grade\"] + 0.01*df[\"attendance\"] + rng.normal(0,0.2,n) > 2.8).astype(int)\n",
    "        return df\n",
    "    frames=[synth(\"INST_A\",[\"LV\",\"LT\",\"IN\",\"LK\",\"IT\",\"FR\"]),\n",
    "            synth(\"INST_B\",[\"IN\",\"LK\",\"PK\",\"BD\",\"DE\",\"PL\"])]\n",
    "\n",
    "data = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "# merge region via culture_map.csv (you already created this)\n",
    "cult_path = DATA/\"culture_map.csv\"\n",
    "if cult_path.exists():\n",
    "    cult = pd.read_csv(cult_path)\n",
    "    data[\"country\"] = data[\"country\"].astype(str).str.upper().str.strip()\n",
    "    data = data.merge(cult, on=\"country\", how=\"left\", suffixes=(\"\",\"_map\"))\n",
    "    mask = data[\"region\"].isna() | (data[\"region\"].astype(str).str.strip().eq(\"\")) | (data[\"region\"]==\"Unknown\")\n",
    "    data.loc[mask, \"region\"] = data.loc[mask, \"region_map\"]\n",
    "    data.drop(columns=[\"region_map\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "print(\"Data preview:\")\n",
    "data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b969aca0-f69e-4398-b9c4-7554d1d51b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cols now: 29\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 3: Temporal features (optional) ---\n",
    "def load_temporal(name):\n",
    "    p = DATA/name\n",
    "    if not p.exists(): return None\n",
    "    t = pd.read_csv(p)\n",
    "    sid = pick_col(t,[r\"^student_?id$\",r\"\\bid$\"], default=t.columns[0])\n",
    "    wk  = pick_col(t,[r\"^week$\",\"wk\",\"time\",\"t\"], default=t.columns[1])\n",
    "    clk = pick_col(t,[\"click\"], default=\"clicks\"); \n",
    "    vid = pick_col(t,[\"video\"], default=\"videos_watched\")\n",
    "    ass = pick_col(t,[\"assign\",\"submission\"], default=\"assignments_submitted\")\n",
    "    for c in [clk,vid,ass]: \n",
    "        if c not in t.columns: t[c]=0\n",
    "    t = t.rename(columns={sid:\"student_id\", wk:\"week\", clk:\"clicks\", vid:\"videos_watched\", ass:\"assignments_submitted\"})\n",
    "    for c in [\"week\",\"clicks\",\"videos_watched\",\"assignments_submitted\"]:\n",
    "        t[c] = pd.to_numeric(t[c], errors=\"coerce\").fillna(0)\n",
    "    return t[[\"student_id\",\"week\",\"clicks\",\"videos_watched\",\"assignments_submitted\"]]\n",
    "\n",
    "tA = load_temporal(\"temporal_A.csv\")\n",
    "tB = load_temporal(\"temporal_B.csv\")\n",
    "temporal = pd.concat([x for x in [tA,tB] if x is not None], ignore_index=True) if (tA is not None or tB is not None) else None\n",
    "\n",
    "if temporal is not None and not temporal.empty:\n",
    "    eng = temporal.groupby('student_id').agg(\n",
    "        clicks_sum=('clicks','sum'),\n",
    "        clicks_mean=('clicks','mean'),\n",
    "        clicks_std=('clicks','std'),\n",
    "        videos_sum=('videos_watched','sum'),\n",
    "        assign_sum=('assignments_submitted','sum'),\n",
    "        weeks=('week','nunique'),\n",
    "        week_max=('week','max')\n",
    "    ).reset_index()\n",
    "\n",
    "    early = temporal[temporal['week']<=3].groupby('student_id').agg(\n",
    "        early_clicks=('clicks','sum'),\n",
    "        early_videos=('videos_watched','sum'),\n",
    "        early_assign=('assignments_submitted','sum'),\n",
    "    ).reset_index()\n",
    "\n",
    "    late_wk = temporal.groupby('student_id')['week'].max().rename('wk_last').reset_index()\n",
    "    tmp_late = temporal.merge(late_wk, on='student_id', how='left')\n",
    "    late = tmp_late[tmp_late['week'] >= tmp_late['wk_last']-2].groupby('student_id').agg(\n",
    "        late_clicks=('clicks','sum'),\n",
    "        late_videos=('videos_watched','sum'),\n",
    "        late_assign=('assignments_submitted','sum'),\n",
    "    ).reset_index()\n",
    "\n",
    "    eng = eng.merge(early, on='student_id', how='left').merge(late, on='student_id', how='left').fillna(0)\n",
    "    eng['eng_rate'] = eng['assign_sum'] / eng['weeks'].replace(0, 1)\n",
    "    eng['clicks_per_week'] = eng['clicks_sum'] / eng['weeks'].replace(0, 1)\n",
    "    eng['late_drop'] = (eng['late_clicks'] < eng['early_clicks']*0.5).astype(int)\n",
    "\n",
    "    data = data.merge(eng, on='student_id', how='left').fillna(0)\n",
    "else:\n",
    "    # create zeros if no temporal\n",
    "    for c in [\"clicks_sum\",\"clicks_mean\",\"clicks_std\",\"videos_sum\",\"assign_sum\",\"weeks\",\n",
    "              \"early_clicks\",\"early_videos\",\"early_assign\",\"late_clicks\",\"late_videos\",\"late_assign\",\n",
    "              \"eng_rate\",\"clicks_per_week\",\"late_drop\"]:\n",
    "        if c not in data.columns: data[c]=0\n",
    "\n",
    "print(\"Cols now:\", len(data.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad6fdac4-b7a4-482d-834c-e924e04613f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 500, np.float64(0.674))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Cell 4: Build X/y and split ---\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data[\"target_success\"] = map_to_binary(data[\"pass_fail\"]).astype(int)\n",
    "\n",
    "cat_cols = [\"institution\",\"country\",\"region\",\"gender\",\"program\",\"language_level\"]\n",
    "for c in cat_cols:\n",
    "    if c not in data.columns: data[c]=\"Unknown\"\n",
    "\n",
    "num_cols = [c for c in data.columns if c not in cat_cols + [\"student_id\",\"pass_fail\",\"target_success\"]\n",
    "            and pd.api.types.is_numeric_dtype(data[c])]\n",
    "\n",
    "X = data[cat_cols + num_cols].copy()\n",
    "y = data[\"target_success\"].copy()\n",
    "groups = data[\"institution\"].copy()  # used for institution-holdout CV later\n",
    "\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, stratify=y, test_size=0.25, random_state=42)\n",
    "len(Xtr), len(Xte), y.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8cd2d7b-da73-4dc7-87c7-4e722dd0dccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RF] AUROC=0.516  F1=0.805  thr=0.372\n",
      "[Hybrid] AUROC=0.516  F1=0.805  P=0.674  R=1.000  Acc=0.674\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 5: Hybrid model ---\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_fscore_support, accuracy_score, precision_recall_curve\n",
    "\n",
    "preproc = ColumnTransformer([\n",
    "    (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\")), (\"sc\", StandardScaler(with_mean=False))]), num_cols),\n",
    "    (\"cat\", Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                      (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True))]), cat_cols)\n",
    "])\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=500, random_state=42, n_jobs=-1)\n",
    "pipe = Pipeline([(\"prep\", preproc), (\"rf\", rf)])\n",
    "pipe.fit(Xtr, ytr)\n",
    "\n",
    "proba_tree = pipe.predict_proba(Xte)[:,1]\n",
    "prec, rec, thr = precision_recall_curve(yte, proba_tree)\n",
    "f1s = 2*prec[:-1]*rec[:-1]/(prec[:-1]+rec[:-1]+1e-9)\n",
    "t_best = thr[np.nanargmax(f1s)] if len(thr) else 0.5\n",
    "pred_tree = (proba_tree >= t_best).astype(int)\n",
    "\n",
    "print(f\"[RF] AUROC={roc_auc_score(yte, proba_tree):.3f}  \"\n",
    "      f\"F1={precision_recall_fscore_support(yte, pred_tree, average='binary')[2]:.3f}  thr={t_best:.3f}\")\n",
    "\n",
    "# Optional LSTM on compact 3-step sequence (early/total/late)\n",
    "USE_DL = False\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers, models\n",
    "    USE_DL = True\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "if USE_DL:\n",
    "    def make_seq(df_rows):\n",
    "        return np.stack([\n",
    "            df_rows[[\"early_clicks\",\"clicks_sum\",\"late_clicks\"]].fillna(0).values,\n",
    "            df_rows[[\"early_videos\",\"videos_sum\",\"late_videos\"]].fillna(0).values,\n",
    "            df_rows[[\"early_assign\",\"assign_sum\",\"late_assign\"]].fillna(0).values\n",
    "        ], axis=-1)  # (n, 3, 3)\n",
    "\n",
    "    tr_mask = X.index.isin(Xtr.index); te_mask = X.index.isin(Xte.index)\n",
    "    seq_X_tr = make_seq(data.loc[tr_mask]); seq_X_te = make_seq(data.loc[te_mask])\n",
    "\n",
    "    inp = layers.Input(shape=(3,3))\n",
    "    x = layers.LSTM(32)(inp); x = layers.Dropout(0.2)(x)\n",
    "    out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    lstm = models.Model(inp,out)\n",
    "    lstm.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"AUC\"])\n",
    "    lstm.fit(seq_X_tr, ytr.values, epochs=12, batch_size=64, validation_split=0.2, verbose=0)\n",
    "    proba_lstm = lstm.predict(seq_X_te, verbose=0).ravel()\n",
    "    proba_final = 0.5*proba_tree + 0.5*proba_lstm\n",
    "else:\n",
    "    proba_final = proba_tree\n",
    "\n",
    "pred_final = (proba_final >= t_best).astype(int)\n",
    "au = roc_auc_score(yte, proba_final)\n",
    "p, r, f1, _ = precision_recall_fscore_support(yte, pred_final, average=\"binary\", zero_division=0)\n",
    "acc = accuracy_score(yte, pred_final)\n",
    "print(f\"[Hybrid] AUROC={au:.3f}  F1={f1:.3f}  P={p:.3f}  R={r:.3f}  Acc={acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94ccc9ed-c405-4133-a58e-06bd77fe60ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Institution-holdout AUROCs: ['0.494', '0.509']  | mean= 0.501\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 6: Institution-holdout (domain generalization) ---\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "gkf = GroupKFold(n_splits=2)  # with A/B\n",
    "cv_scores=[]\n",
    "for tr_idx, te_idx in gkf.split(X, y, groups=groups):\n",
    "    X_tr, X_te = X.iloc[tr_idx], X.iloc[te_idx]\n",
    "    y_tr, y_te = y.iloc[tr_idx], y.iloc[te_idx]\n",
    "    p = Pipeline([(\"prep\", preproc), (\"rf\", RandomForestClassifier(n_estimators=500, random_state=42, n_jobs=-1))])\n",
    "    p.fit(X_tr, y_tr)\n",
    "    au = roc_auc_score(y_te, p.predict_proba(X_te)[:,1]) if len(np.unique(y_te))>1 else np.nan\n",
    "    cv_scores.append(au)\n",
    "print(\"Institution-holdout AUROCs:\", [f\"{x:.3f}\" for x in cv_scores], \" | mean=\", f\"{np.nanmean(cv_scores):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6486ce5f-a10b-405c-af1a-9a7f88ce5149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By country:\n",
      "   country   n     auroc        f1       acc  pos_rate\n",
      "5      LK  84  0.490434  0.800000  0.666667       1.0\n",
      "7      LV  82  0.632277  0.836879  0.719512       1.0\n",
      "0      DE  72  0.488511  0.789916  0.652778       1.0\n",
      "4      IT  66  0.500000  0.810811  0.681818       1.0\n",
      "3      IN  66  0.561376  0.810811  0.681818       1.0\n",
      "1      EE  38  0.544872  0.812500  0.684211       1.0\n",
      "8      PL  35  0.340909  0.813559  0.685714       1.0\n",
      "2      ES  31  0.504202  0.708333  0.548387       1.0\n",
      "6      LT  26  0.586806  0.818182  0.692308       1.0\n",
      "\n",
      "Fairness gaps:\n",
      " dp_gap_country    0.0\n",
      "dp_gap_region     0.0\n",
      "eo_gap_country    0.0\n",
      "eo_gap_region     0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 7: Culture/region metrics + fairness ---\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "\n",
    "test_df = Xte.reset_index(drop=True).copy()\n",
    "test_df[\"success\"] = yte.reset_index(drop=True).values\n",
    "test_df[\"y_prob\"]  = proba_final[:len(test_df)]\n",
    "test_df[\"y_pred\"]  = (proba_final >= t_best).astype(int)\n",
    "\n",
    "for c in [\"country\",\"region\",\"institution\"]:\n",
    "    if c not in test_df.columns: test_df[c] = \"Unknown\"\n",
    "\n",
    "def group_metrics(df, group_col):\n",
    "    rows=[]\n",
    "    for g, sub in df.groupby(group_col):\n",
    "        yt, yp, yhat = sub[\"success\"].values, sub[\"y_prob\"].values, sub[\"y_pred\"].values\n",
    "        rows.append({\n",
    "            group_col: g, \"n\": int(len(yt)),\n",
    "            \"auroc\": float(roc_auc_score(yt, yp)) if len(np.unique(yt))>1 else np.nan,\n",
    "            \"f1\": float(f1_score(yt, yhat)) if len(np.unique(yt))>1 else np.nan,\n",
    "            \"acc\": float(accuracy_score(yt, yhat)),\n",
    "            \"pos_rate\": float(np.mean(yhat))\n",
    "        })\n",
    "    return pd.DataFrame(rows).sort_values(\"n\", ascending=False)\n",
    "\n",
    "by_country = group_metrics(test_df, \"country\")\n",
    "by_region  = group_metrics(test_df, \"region\")\n",
    "by_inst    = group_metrics(test_df, \"institution\")\n",
    "\n",
    "def dp_gap(df, col):\n",
    "    rates = df.groupby(col)[\"y_pred\"].mean()\n",
    "    return float(rates.max()-rates.min()) if len(rates)>1 else 0.0\n",
    "\n",
    "def eo_gap(df, col):\n",
    "    vals=[]\n",
    "    for g, sub in df.groupby(col):\n",
    "        pos = (sub[\"success\"]==1)\n",
    "        if pos.sum(): vals.append((sub.loc[pos,\"y_pred\"]==1).mean())\n",
    "    return float(np.nanmax(vals)-np.nanmin(vals)) if len(vals)>1 else 0.0\n",
    "\n",
    "fairness = pd.Series({\n",
    "    \"dp_gap_country\": dp_gap(test_df,\"country\"),\n",
    "    \"dp_gap_region\" : dp_gap(test_df,\"region\"),\n",
    "    \"eo_gap_country\": eo_gap(test_df,\"country\"),\n",
    "    \"eo_gap_region\" : eo_gap(test_df,\"region\"),\n",
    "})\n",
    "\n",
    "bins = np.linspace(0,1,11)\n",
    "bin_ids = np.digitize(test_df[\"y_prob\"], bins)-1\n",
    "cal_df = (test_df.assign(bin=bin_ids)\n",
    "          .groupby(\"bin\")\n",
    "          .agg(prob_pred_bin_mean=(\"y_prob\",\"mean\"),\n",
    "               frac_pos=(\"y_pred\",\"mean\"))\n",
    "          .dropna()\n",
    "          .reset_index(drop=True))\n",
    "\n",
    "cm = confusion_matrix(test_df[\"success\"], test_df[\"y_pred\"])\n",
    "cm_df = pd.DataFrame(cm, index=[\"Actual 0\",\"Actual 1\"], columns=[\"Pred 0\",\"Pred 1\"])\n",
    "\n",
    "print(\"By country:\\n\", by_country.head(10))\n",
    "print(\"\\nFairness gaps:\\n\", fairness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c011cb68-d908-4808-9481-e6e6f5fd7fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts saved to: C:\\Users\\kule9\\final\\artifacts\n",
      "Open: C:\\Users\\kule9\\final\\artifacts\\dashboard.html\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 8: Save artifacts + dashboard ---\n",
    "by_country.to_csv(ART/\"metrics_by_country.csv\", index=False)\n",
    "by_region.to_csv(ART/\"metrics_by_region.csv\", index=False)\n",
    "by_inst.to_csv(ART/\"metrics_by_institution.csv\", index=False)\n",
    "fairness.to_csv(ART/\"fairness_gaps.csv\", header=False)\n",
    "cal_df.to_csv(ART/\"calibration_curve.csv\", index=False)\n",
    "cm_df.to_csv(ART/\"confusion_matrix.csv\")\n",
    "test_df.to_csv(ART/\"scored_students.csv\", index=False)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_fscore_support, accuracy_score\n",
    "p, r, f1, _ = precision_recall_fscore_support(test_df[\"success\"], test_df[\"y_pred\"], average=\"binary\", zero_division=0)\n",
    "acc = accuracy_score(test_df[\"success\"], test_df[\"y_pred\"])\n",
    "au  = roc_auc_score(test_df[\"success\"], test_df[\"y_prob\"]) if len(np.unique(test_df[\"success\"]))>1 else np.nan\n",
    "\n",
    "html = f\"\"\"\n",
    "<html><head><meta charset='utf-8'><title>Cross-Cultural Hybrid Framework</title>\n",
    "<style>body{{font-family:Arial;padding:18px}} table{{border-collapse:collapse}} td,th{{border:1px solid #ccc;padding:6px}}</style>\n",
    "</head><body>\n",
    "<h1>Predicting Student Academic Success â€” Hybrid Model</h1>\n",
    "<h3>Global Test Metrics</h3>\n",
    "<p>AUROC={au:.3f} | F1={f1:.3f} | P={p:.3f} | R={r:.3f} | Acc={acc:.3f} | Threshold={float(np.round(test_df['y_pred'].mean(),3))}</p>\n",
    "<h3>By Country</h3>{by_country.to_html(index=False)}\n",
    "<h3>By Region</h3>{by_region.to_html(index=False)}\n",
    "<h3>By Institution</h3>{by_inst.to_html(index=False)}\n",
    "<h3>Fairness Gaps</h3><pre>{fairness.to_string()}</pre>\n",
    "<h3>Calibration bins</h3>{cal_df.to_html(index=False)}\n",
    "<h3>Confusion Matrix</h3>{cm_df.to_html()}\n",
    "</body></html>\n",
    "\"\"\"\n",
    "(ART/\"dashboard.html\").write_text(html, encoding=\"utf-8\")\n",
    "print(\"Artifacts saved to:\", ART)\n",
    "print(\"Open:\", ART/\"dashboard.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326f1980-0d9b-44ec-be5b-beff83717245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb2322d-5645-451f-995c-81a9057d7ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
